{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:51:35.301049Z",
     "start_time": "2025-09-22T19:51:35.286050Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64523a3577bca00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ee478b07b643f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T20:08:30.136334Z",
     "start_time": "2025-09-22T20:08:29.945746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exe: C:\\Users\\kubilay\\PycharmProjects\\gpt-2-124M\\.venv\\Scripts\\python.exe\n",
      "TF: 2.20.0\n",
      "transformers TF görüyor mu?: True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_tf_available\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers TF görüyor mu?:\u001b[39m\u001b[38;5;124m\"\u001b[39m, is_tf_available())\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TFGPT2LMHeadModel, AutoTokenizer\n\u001b[0;32m      8\u001b[0m tok \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m TFGPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:2302\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[0;32m   2301\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2302\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2303\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2304\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:2332\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:2330\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2330\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     28\u001b[0m     TFCausalLMOutputWithCrossAttentions,\n\u001b[0;32m     29\u001b[0m     TFSequenceClassifierOutputWithPast,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     TFCausalLanguageModelingLoss,\n\u001b[0;32m     33\u001b[0m     TFConv1D,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     unpack_inputs,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    initially created. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Also see\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    https://huggingface.co/papers/1606.08415\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "import sys, tensorflow as tf\n",
    "print(\"exe:\", sys.executable)\n",
    "print(\"TF:\", tf.__version__)\n",
    "from transformers.utils import is_tf_available\n",
    "print(\"transformers TF görüyor mu?:\", is_tf_available())\n",
    "\n",
    "from transformers import TFGPT2LMHeadModel, AutoTokenizer\n",
    "tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "print(\"OK:\", type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656588484b29da85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:56:16.589588Z",
     "start_time": "2025-09-22T19:56:13.981283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (6.30.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (8.37.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (4.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (311)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\kubilay\\pycharmprojects\\gpt-2-124m\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec tf220 in C:\\Users\\kubilay\\AppData\\Roaming\\jupyter\\kernels\\tf220\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel\n",
    "!python -m ipykernel install --user --name=tf220 --display-name \"Python (tf220)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f4a3a2cb379838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:56:24.307575Z",
     "start_time": "2025-09-22T19:56:24.276327Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nTFGPT2LMHeadModel requires the TensorFlow library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFGPT2LMHeadModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:2142\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_dummy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 2142\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\gpt-2-124M\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:2128\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         failed\u001b[38;5;241m.\u001b[39mappend(msg\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 2128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nTFGPT2LMHeadModel requires the TensorFlow library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa8aecf53d6038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf220)",
   "language": "python",
   "name": "tf220"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
